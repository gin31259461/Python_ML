{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Type\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# * References\n",
    "# MNIST dataset: http://yann.lecun.com/exdb/mnist/\n",
    "# Image Classification with MNIST Dataset: https://debuggercafe.com/image-classification-with-mnist-dataset/\n",
    "# Improving accuracy on MNIST: https://towardsdatascience.com/improving-accuracy-on-mnist-using-data-augmentation-b5c38eb5a903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenML: https://www.openml.org/search?type=data&status=active\n",
    "\n",
    "# mnist_data = fetch_openml(\"Fashion-MNIST\", parser=\"auto\", version=\"1\")\n",
    "\n",
    "# 0 T-shirt/top\n",
    "# 1 Trouser\n",
    "# 2 Pullover\n",
    "# 3 Dress\n",
    "# 4 Coat\n",
    "# 5 Sandal\n",
    "# 6 Shirt\n",
    "# 7 Sneaker\n",
    "# 8 Bag\n",
    "# 9 Ankle boot\n",
    "\n",
    "mnist_data = fetch_openml(\"mnist_784\", parser=\"auto\", version=\"1\")\n",
    "\n",
    "data: Type[pd.DataFrame] = mnist_data[\"data\"]\n",
    "target: Type[pd.DataFrame] = mnist_data[\"target\"]\n",
    "\n",
    "# Normalize the X (training set)\n",
    "X, y = (data / 255).values.tolist(), target.values.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "origin_train_length = len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot partial mnist image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotMnistImage(image: list[list[int]], labels: list[int]):\n",
    "    for i in range(9):\n",
    "        image_pixels = np.array(image[i]).reshape(28, 28)\n",
    "        axis = pyplot.subplot(3, 3, i + 1)\n",
    "        axis.get_xaxis().set_visible(False)\n",
    "        axis.get_yaxis().set_visible(False)\n",
    "        axis.set_title(labels[i])\n",
    "        # pyplot.gray()\n",
    "        pyplot.imshow(image_pixels)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "PlotMnistImage(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: SGDClassifier accuracy\n",
    "\n",
    "Use <span style='color:lightblue'><strong>SGDClassifier</strong></span> for the <span style='color:lightblue'><strong>MNIST</strong></span> dataset and measure the <span style='color:lightblue'><strong>accuracy</strong></span> (the ratio of correct predictions) using cross-validation (cv=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, use the default hyperparameter setting\n",
    "sgd_clf = SGDClassifier(random_state=42, n_jobs=-1)\n",
    "model = sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_predict = sgd_clf.predict(X_test)\n",
    "\n",
    "evaluation = confusion_matrix(y_test, y_predict)\n",
    "display = ConfusionMatrixDisplay(evaluation, display_labels=sgd_clf.classes_)\n",
    "display.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f\"Classification report for classifier {sgd_clf}:\\n\" f\"{classification_report(y_test, y_predict)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def CrossValidationAccuracy(estimator: Type[BaseEstimator], X_train, y_train):\n",
    "    score = cross_val_score(estimator=estimator, X=X_train, y=y_train, cv=3, scoring=\"accuracy\")\n",
    "    print(f\"Cross validation accuracy: {score}\")\n",
    "    print(f\"Cross validation accuracy mean: {np.mean(score)}\")\n",
    "\n",
    "\n",
    "def TestingAccuracy(estimator: Type[BaseEstimator], X_test, y_test):\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_predict)\n",
    "    print(f\"Accuracy of test set: {score}\")\n",
    "\n",
    "\n",
    "CrossValidationAccuracy(sgd_clf, X_train, y_train)\n",
    "TestingAccuracy(sgd_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Data Augmentation\n",
    "\n",
    "Using <span style='color:lightblue'><strong>Data Augmentation</strong></span> (artificially growing the training set) to see if the accuracy can be improved.\n",
    "\n",
    "Note: You may write a function that can shift an MNIST image in any direction (left, right,\n",
    "up, or down) by one pixel. Then, for each image in the training set, create four shifted\n",
    "copies (one per direction) and add them to the training set. Finally, train your model\n",
    "on this expanded training set and measure its accuracy on the test/validation set. (You\n",
    "should not allow data obtained by augmentation of the training part leak into the\n",
    "test/validation set.)\n",
    "\n",
    "Ref: You can use the <span style='color:lightblue'><strong>shift()</strong></span> function from the <span style='color:lightblue'><strong>scipy.ndimage.interpolation</strong></span> module. For\n",
    "example, shift(image, [2, 1], cval=0) shifts the image two pixels down and one pixel\n",
    "to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.ndimage.interpolation namespace is deprecated => use scipy.ndimage namespace\n",
    "from scipy.ndimage import shift\n",
    "\n",
    "\n",
    "def shift_image(image: Type[np.ndarray], dy, dx):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape((-1))\n",
    "\n",
    "\n",
    "def MnistDataAugmentation(X_train: list, y_train: list, shift_bias) -> list:\n",
    "    # left, right, up, down\n",
    "    shiftParams = [[0, -shift_bias], [0, shift_bias], [-shift_bias, 0], [shift_bias, 0]]\n",
    "    expanded_X_train = []\n",
    "    expanded_y_train = []\n",
    "\n",
    "    for s in shiftParams:\n",
    "        shifted_image = [shift_image(np.array(X_train[i]), s[0], s[1]) for i in range(len(X_train))]\n",
    "        expanded_X_train.extend(shifted_image)\n",
    "        expanded_y_train.extend(y_train)\n",
    "\n",
    "    X_train.extend(expanded_X_train)\n",
    "    y_train.extend(expanded_y_train)\n",
    "\n",
    "\n",
    "print(f\"Before augmentation training set length: {len(X_train)}\")\n",
    "\n",
    "expanded_X_train, expanded_y_train = X_train.copy(), y_train.copy()\n",
    "MnistDataAugmentation(expanded_X_train, expanded_y_train, 1)\n",
    "\n",
    "print(f\"After augmentation training set length: {len(expanded_X_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorganize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "shuffle_idx = np.random.permutation(len(expanded_X_train))\n",
    "X_train_augmented = np.array(expanded_X_train)[shuffle_idx]\n",
    "y_train_augmented = np.array(expanded_y_train)[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42, n_jobs=-1)\n",
    "model = sgd_clf.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "\n",
    "CrossValidationAccuracy(sgd_clf, X_train_augmented, y_train_augmented)\n",
    "TestingAccuracy(sgd_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Improve the performance\n",
    "\n",
    "<span style=\"color:red\"><strong>(Bonus)</strong></span> Is there any technique (such as <span style=\"color:lightblue\"><strong>normalization</strong></span> or <span style=\"color:lightblue\"><strong>hyperparameter</strong></span> tuning for SGDClassifier)\n",
    "that can further improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "#     \"max_iter\": [100, 500, 1000],\n",
    "#     \"penalty\": [\"l1\", \"l2\"],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=SGDClassifier(\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#     ),\n",
    "#     param_grid=param_grid,\n",
    "#     verbose=1,\n",
    "#     cv=5,\n",
    "# )\n",
    "\n",
    "# shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "# sample_size = np.array(range(int(len(shuffle_idx))))\n",
    "\n",
    "# random_X_train = X_train_augmented[shuffle_idx[sample_size]]\n",
    "# random_y_train = y_train_augmented[shuffle_idx[sample_size]]\n",
    "\n",
    "# grid_search.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# print(f\"Best score: {grid_search.best_score_}\")\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# best_sgd_clf = grid_search.best_estimator_\n",
    "# best_sgd_clf.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# TestingAccuracy(best_sgd_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover\n",
    "\n",
    "- 如果訓練資料沒有經過標準化，訓練時間會加長，且模型精確度也會比標準化過的訓練資料低\n",
    "- Partial fit (增量訓練) 可以增強模型訓練的效能\n",
    "- Shuffle the new training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Confusion matrix\n",
    "Using <span style=\"color:lightblue\"><strong>the confusion matrix</strong></span> to gain insights for performance evaluation/comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = sgd_clf.predict(X_test)\n",
    "\n",
    "evaluation = confusion_matrix(y_test, y_predict)\n",
    "display = ConfusionMatrixDisplay(evaluation, display_labels=sgd_clf.classes_)\n",
    "display.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification report for classifier {sgd_clf}:\\n\" f\"{classification_report(y_test, y_predict)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
